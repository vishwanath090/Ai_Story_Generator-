{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (2.15.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (1.23.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (2.0.3)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.24.2)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.57.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.3.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\91807\\appdata\\roaming\\python\\python310\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\91807\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Attention\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "def load_data(source_path, target_path):\n",
    "    with open(source_path, 'r', encoding='utf-8') as f:\n",
    "        sources = f.readlines()\n",
    "    with open(target_path, 'r', encoding='utf-8') as f:\n",
    "        targets = f.readlines()\n",
    "    return sources, targets\n",
    "\n",
    "train_sources, train_targets = load_data(\n",
    "    \"C:\\\\Users\\\\91807\\\\OneDrive\\\\Desktop\\\\TOC\\\\writingPrompts\\\\train.wp_source\",\n",
    "    \"C:\\\\Users\\\\91807\\\\OneDrive\\\\Desktop\\\\TOC\\\\writingPrompts\\\\train.wp_target\"\n",
    ")\n",
    "valid_sources, valid_targets = load_data(\n",
    "    \"C:\\\\Users\\\\91807\\\\OneDrive\\\\Desktop\\\\TOC\\\\writingPrompts\\\\valid.wp_source\",\n",
    "    \"C:\\\\Users\\\\91807\\\\OneDrive\\\\Desktop\\\\TOC\\\\writingPrompts\\\\valid.wp_target\"\n",
    ")\n",
    "test_sources, test_targets = load_data(\n",
    "    \"C:\\\\Users\\\\91807\\\\OneDrive\\\\Desktop\\\\TOC\\\\writingPrompts\\\\test.wp_source\",\n",
    "    \"C:\\\\Users\\\\91807\\\\OneDrive\\\\Desktop\\\\TOC\\\\writingPrompts\\\\test.wp_target\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess data\n",
    "def preprocess_data(sources, targets, max_vocab_size=50000, max_seq_length=100):\n",
    "    tokenizer = Tokenizer(num_words=max_vocab_size, oov_token=\"<OOV>\")\n",
    "    tokenizer.fit_on_texts(sources + targets)\n",
    "\n",
    "    source_sequences = tokenizer.texts_to_sequences(sources)\n",
    "    target_sequences = tokenizer.texts_to_sequences(targets)\n",
    "\n",
    "    source_padded = pad_sequences(source_sequences, maxlen=max_seq_length, padding='post')\n",
    "    target_padded = pad_sequences(target_sequences, maxlen=max_seq_length+1, padding='post')\n",
    "\n",
    "    return source_padded, target_padded, tokenizer\n",
    "\n",
    "train_source_padded, train_target_padded, tokenizer = preprocess_data(train_sources, train_targets)\n",
    "valid_source_padded, valid_target_padded, _ = preprocess_data(valid_sources, valid_targets)\n",
    "test_source_padded, test_target_padded, _ = preprocess_data(test_sources, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\91807\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\91807\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 100)]                0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 100)]                0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 100, 256)             1280000   ['input_1[0][0]']             \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, 100, 256)             1280000   ['input_2[0][0]']             \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(None, 100, 512),           1574912   ['embedding[0][0]']           \n",
      "                              (None, 512),                                                        \n",
      "                              (None, 512)]                                                        \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               [(None, 100, 512),           1574912   ['embedding_1[0][0]',         \n",
      "                              (None, 512),                           'lstm[0][1]',                \n",
      "                              (None, 512)]                           'lstm[0][2]']                \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, 100, 512)             0         ['lstm_1[0][0]',              \n",
      "                                                                     'lstm[0][0]']                \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)      (None, 100, 1024)            0         ['lstm_1[0][0]',              \n",
      "                                                                     'attention[0][0]']           \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 100, 50000)           5125000   ['tf.concat[0][0]']           \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 79999824 (305.18 MB)\n",
      "Trainable params: 79999824 (305.18 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#BUILD MODEL\n",
    "def build_model(max_vocab_size, embedding_dim, hidden_units, max_seq_length):\n",
    "    # Encoder\n",
    "    encoder_inputs = Input(shape=(max_seq_length,))\n",
    "    encoder_embedding = Embedding(input_dim=max_vocab_size, output_dim=embedding_dim)(encoder_inputs)\n",
    "    encoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True)\n",
    "    encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    # Decoder\n",
    "    decoder_inputs = Input(shape=(max_seq_length,))\n",
    "    decoder_embedding = Embedding(input_dim=max_vocab_size, output_dim=embedding_dim)(decoder_inputs)\n",
    "    decoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "\n",
    "    # Attention\n",
    "    attention = Attention()([decoder_outputs, encoder_outputs])\n",
    "    decoder_concat = tf.concat([decoder_outputs, attention], axis=-1)\n",
    "\n",
    "    # Dense Layer\n",
    "    decoder_dense = Dense(max_vocab_size, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_concat)\n",
    "\n",
    "    # Model\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_model(max_vocab_size=50000, embedding_dim=256, hidden_units=512, max_seq_length=100)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\91807\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\91807\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "  58/4260 [..............................] - ETA: 100:29:10 - loss: 7.3439 - accuracy: 0.0625"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [train_source_padded, train_target_padded[:, :-1]],  # Input shape: (None, 100)\n",
    "    train_target_padded[:, 1:],                          # Output shape: (None, 100)\n",
    "    batch_size=64,\n",
    "    epochs=10,\n",
    "    validation_data=([valid_source_padded, valid_target_padded[:, :-1]], valid_target_padded[:, 1:])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"story_generation_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and generate story\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"story_generation_model.h5\")\n",
    "\n",
    "def generate_story(prompt, model, tokenizer, max_seq_length=100):\n",
    "    prompt_seq = tokenizer.texts_to_sequences([prompt])\n",
    "    prompt_padded = pad_sequences(prompt_seq, maxlen=max_seq_length, padding='post')\n",
    "\n",
    "    # Initialize decoder input with start token\n",
    "    decoder_input = np.zeros((1, max_seq_length))\n",
    "    decoder_input[0, 0] = tokenizer.word_index['<start>']\n",
    "\n",
    "    # Generate story\n",
    "    for i in range(1, max_seq_length):\n",
    "        predictions = model.predict([prompt_padded, decoder_input])\n",
    "        predicted_id = np.argmax(predictions[0, i-1, :])\n",
    "        decoder_input[0, i] = predicted_id\n",
    "        if predicted_id == tokenizer.word_index['<end>']:\n",
    "            break\n",
    "\n",
    "    # Convert sequence to text\n",
    "    story = tokenizer.sequences_to_texts(decoder_input)[0]\n",
    "    return story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flask api\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/generate', methods=['POST'])\n",
    "def generate():\n",
    "    data = request.json\n",
    "    prompt = data.get('prompt')\n",
    "    story = generate_story(prompt, model, tokenizer)\n",
    "    return jsonify({\"story\": story})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
